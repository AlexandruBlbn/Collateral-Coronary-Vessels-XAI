import os
import sys
import yaml
import torch
import torch.nn.functional as F
import numpy as np
import gradio as gr
from PIL import Image
import torchvision.transforms as transforms
import matplotlib.cm as cm

# --- SETUP CÄ‚I (PATHS) ---
# AdÄƒugÄƒm root-ul proiectului Ã®n path pentru a putea importa din 'zoo'
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, '../../')
sys.path.append(project_root)

from zoo.backbones import get_backbone

# --- CONFIGURARE ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# Calea relativÄƒ cÄƒtre config (ajusteazÄƒ dacÄƒ e diferitÄƒ)
CONFIG_PATH = os.path.join(project_root, "config/dino_config.yaml")

def load_config():
    if not os.path.exists(CONFIG_PATH):
        print(f"Eroare: Config file nu existÄƒ la {CONFIG_PATH}")
        sys.exit(1)
    with open(CONFIG_PATH, "r") as f:
        return yaml.safe_load(f)

def get_model_and_transform():
    config = load_config()
    
    backbone_name = config["model"]["backbone"]
    in_channels = config["data"].get("in_channels", 3)
    experiment_name = config.get("experiment_name", f"dino_{backbone_name}")
    
    print(f"--> Loading Backbone: {backbone_name}")
    
    # 1. IniÈ›ializare Model (Backbone gol)
    model = get_backbone(model_name=backbone_name, in_channels=in_channels, pretrained=False)
    model.to(DEVICE)
    model.eval()
    
    # 2. CÄƒutare Checkpoint (Best Backbone)
    # CÄƒutÄƒm Ã®n mai multe locuri posibile
    possible_paths = [
        os.path.join(project_root, "checkpoints/dino", experiment_name, "last_backbone.pth"),
        f"./checkpoints/dino/{experiment_name}/best_backbone.pth"
    ]
    
    ckpt_path = None
    for p in possible_paths:
        if os.path.exists(p):
            ckpt_path = p
            break
            
    if ckpt_path:
        print(f"--> Loading weights from: {ckpt_path}")
        state = torch.load(ckpt_path, map_location=DEVICE)
        
        # CurÄƒÈ›are prefixe (student.backbone, encoder, etc.)
        clean_state = {}
        for k, v in state.items():
            k = k.replace("backbone.", "").replace("encoder.", "").replace("student_backbone.", "").replace("student.", "")
            clean_state[k] = v
            
        msg = model.load_state_dict(clean_state, strict=False)
        print(f"--> Weights loaded. Missing keys (head keys are normal): {len(msg.missing_keys)}")
    else:
        print(f"âš  WARNING: Checkpoint not found! Using RANDOM weights. (Path cautat: {possible_paths[0]})")

    # 3. Transformare
    # Resize la 256x256 pentru vitezÄƒ È™i consistenÈ›Äƒ cu antrenamentul
    input_size = config["model"].get("input_size", 256)
    transform = transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])
    
    return model, transform, in_channels

# --- GLOBAL CACHE ---
# ÃncÄƒrcÄƒm modelul o singurÄƒ datÄƒ la start
MODEL, TRANSFORM, IN_CHANNELS = get_model_and_transform()
CURRENT_FEATURES = None # Aici stocÄƒm feature-urile imaginii curente
CURRENT_SHAPE = None    # Dimensiunile originale ale imaginii

def extract_features(input_img_numpy):
    """
    Pasul 1: Preia imaginea, o trece prin backbone È™i salveazÄƒ feature map-ul.
    """
    global CURRENT_FEATURES, CURRENT_SHAPE
    
    if input_img_numpy is None:
        return "Te rog Ã®ncarcÄƒ o imagine."
    
    # input_img_numpy vine de la Gradio ca (H, W, 3) uint8
    pil_img = Image.fromarray(input_img_numpy)
    
    # Convertim la Grayscale sau RGB Ã®n funcÈ›ie de model
    if IN_CHANNELS == 1:
        pil_img = pil_img.convert('L')
    else:
        pil_img = pil_img.convert('RGB')
        
    CURRENT_SHAPE = pil_img.size # (W, H)
    
    # Preprocesare
    img_tensor = TRANSFORM(pil_img).unsqueeze(0).to(DEVICE) # (1, C, H, W)
    
    with torch.no_grad():
        # Extragem features. Rezultat tipic: (1, 384, 16, 16) pentru ViT-Small
        features = MODEL(img_tensor)
        
        # DacÄƒ output-ul e (B, N, D) (ViT standard), facem reshape la grid
        if len(features.shape) == 3:
            B, N, D = features.shape
            # Presupunem grid pÄƒtrat (ex: 256/16 = 16x16 patch-uri -> 256 tokens)
            H_grid = W_grid = int(np.sqrt(N)) 
            # (B, N, D) -> (B, D, H, W)
            features = features.transpose(1, 2).reshape(B, D, H_grid, W_grid)
            
    # Normalizare L2 (Crucial pentru Cosine Similarity)
    # DupÄƒ normalizare, Dot Product == Cosine Similarity
    features = F.normalize(features, dim=1, p=2)
    
    CURRENT_FEATURES = features
    return f"âœ… Features extrase! Shape: {tuple(features.shape)}. Acum dÄƒ click pe imagine."

def query_point(evt: gr.SelectData, input_image):
    """
    Pasul 2: CÃ¢nd userul dÄƒ click, comparÄƒm vectorul de sub cursor cu toÈ›i ceilalÈ›i.
    """
    global CURRENT_FEATURES
    
    if CURRENT_FEATURES is None:
        return input_image # Nu s-au extras features Ã®ncÄƒ
    
    # Coordonatele click-ului (Ã®n pixeli pe imaginea originalÄƒ)
    x, y = evt.index[0], evt.index[1]
    
    # Dimensiunile imaginii afiÈ™ate
    H_img, W_img = input_image.shape[0], input_image.shape[1]
    
    # Dimensiunile Grid-ului de Features (ex: 16x16)
    B, Dim, H_feat, W_feat = CURRENT_FEATURES.shape
    
    # MapÄƒm coordonatele din Imagine -> Grid
    grid_x = int(x / W_img * W_feat)
    grid_y = int(y / H_img * H_feat)
    
    # Clamp pentru a nu ieÈ™i din matrice
    grid_x = min(max(grid_x, 0), W_feat - 1)
    grid_y = min(max(grid_y, 0), H_feat - 1)
    
    # --- PROBING MAGIC ---
    
    # 1. LuÄƒm "SemnÄƒtura" punctului selectat (Vectorul Query)
    query_vector = CURRENT_FEATURES[:, :, grid_y, grid_x].unsqueeze(-1).unsqueeze(-1) # (1, D, 1, 1)
    
    # 2. Produs scalar cu toatÄƒ harta (Cosine Similarity)
    # Rezultat: O hartÄƒ de cÄƒldurÄƒ (1, H_feat, W_feat) cu valori Ã®ntre -1 È™i 1
    similarity_map = torch.sum(CURRENT_FEATURES * query_vector, dim=1) 
    
    # 3. Post-procesare pentru vizualizare clarÄƒ
    # TÄƒiem valorile negative (ce nu seamÄƒnÄƒ deloc)
    heatmap = similarity_map.clamp(min=0)
    
    # RidicÄƒm la putere pentru a evidenÈ›ia doar zonele FOARTE similare
    # DINO Ã®nvaÈ›Äƒ reprezentÄƒri foarte ascuÈ›ite, aÈ™a cÄƒ ^3 sau ^4 aratÄƒ bine
    heatmap = heatmap ** 3 
    
    # 4. Upscaling Ã®napoi la rezoluÈ›ia imaginii
    heatmap = F.interpolate(heatmap.unsqueeze(0), size=(H_img, W_img), mode='bicubic', align_corners=False)
    heatmap = heatmap.squeeze().cpu().numpy()
    
    # Normalizare 0-1 pentru plotare
    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
    
    # 5. Colorare (Jet: Albastru=0, RoÈ™u=1)
    heatmap_colored = cm.jet(heatmap)[:, :, :3] # RGB
    
    # 6. Overlay
    if len(input_image.shape) == 2:
        input_image = np.stack([input_image]*3, axis=-1)
        
    img_float = input_image.astype(float) / 255.0
    
    # Mix: 30% Imagine OriginalÄƒ + 70% Heatmap
    overlay = 0.3 * img_float + 0.7 * heatmap_colored
    overlay = np.clip(overlay, 0, 1)
    
    return (overlay * 255).astype(np.uint8)

# --- INTERFAÈšA GRADIO ---
with gr.Blocks(title="DINO Anatomical Probing", theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # ğŸ§  DINO Dense Feature Probing
        **Cum funcÈ›ioneazÄƒ:**
        1. Modelul transformÄƒ imaginea Ã®ntr-o grilÄƒ de vectori (semnÄƒturi semantice).
        2. CÃ¢nd dai click, luÄƒm vectorul de sub cursor.
        3. ColorÄƒm cu **RoÈ™u** zonele care au o semnÄƒturÄƒ similarÄƒ.
        
        **Ce sÄƒ cauÈ›i:** DacÄƒ dai click pe un vas de sÃ¢nge, ar trebui sÄƒ se aprindÄƒ DOAR alte vase de sÃ¢nge.
        """
    )
    
    with gr.Row():
        with gr.Column():
            input_img = gr.Image(label="1. ÃncarcÄƒ Angiografia", type="numpy")
            btn_extract = gr.Button("2. Extract Features (RuleazÄƒ Backbone)", variant="primary")
            status_msg = gr.Textbox(label="Status", value="AÈ™tept imagine...", interactive=False)
        
        with gr.Column():
            output_img = gr.Image(label="3. Rezultat Probing (Click pe imaginea din stÃ¢nga!)", interactive=False)
            
    # LegÄƒturi Evenimente
    btn_extract.click(extract_features, inputs=input_img, outputs=status_msg)
    input_img.select(query_point, inputs=input_img, outputs=output_img)

if __name__ == "__main__":
    print(f"Pornire server pe port 7860...")
    # share=True face un link public temporar (util dacÄƒ eÈ™ti pe un server cloud)
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)